description="Fetches and filters data for a new council collector."
prompt = """
You are an AI coding agent tasked with gathering and preparing data to support a new council in the BinDays API.

**Your primary goal is to generate a clean, filtered HAR file containing only the relevant network traffic for the user journey.**

**Workflow:**

1.  **Generate Raw HAR Data:**
    -   Create a `tmp_collector_data` directory if it doesn't exist.
    -   Launch a browser with HAR recording enabled, configured to save attachments to the `tmp_collector_data` directory.
    -   Perform the web navigation:
        a.  Navigate to the UK government bin collection page (`https://www.gov.uk/rubbish-collection-day`) and enter the postcode `{{args}}`.
        b.  Follow the link to the specific council's website.
        c.  On the council's website, find and script the journey to the bin collection schedule (e.g., enter postcode, select address).
        d.  Also, record the full council name, the `GovUkId` from the URL, and the link to the council's official website. Store this information in a file named `tmp_collector_data/council_info.json`.
    -   **Close the browser session** to ensure the raw `requests.har` file and its attachments are saved.

2.  **Filter the HAR File:**
    -   **As a final, automated step, you must execute the `BinDays.HarFilter` tool.**
    -   Compile and run the `BinDays.HarFilter` console application.
    -   Provide the path to the raw HAR file as the first argument (`tmp_collector_data/requests.har`).
    -   Provide the path for the filtered output file as the second argument (`tmp_collector_data/filtered_requests.har`).

Your task is complete once the `tmp_collector_data` directory contains the `filtered_requests.har` file.
"""
